#!/usr/bin/env python3
"""
Batch Dossier Generation Test - Multiple Entities with Markdown Export
"""

import asyncio
import sys
import os
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add backend to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from dossier_generator import EntityDossierGenerator
from claude_client import ClaudeClient


def save_dossier_as_markdown(dossier, output_dir="data/dossiers"):
    """Save dossier as formatted markdown file"""

    # Create output directory
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Create filename
    safe_name = dossier.entity_name.lower().replace(" ", "-").replace("/", "-")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{safe_name}_dossier_{timestamp}.md"
    filepath = os.path.join(output_dir, filename)

    # Build markdown content
    md_content = []

    # Header
    md_content.append(f"# {dossier.entity_name} - Entity Dossier\n")
    md_content.append(f"**Generated**: {dossier.generated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
    md_content.append(f"**Entity ID**: {dossier.entity_id}\n")
    md_content.append(f"**Entity Type**: {dossier.entity_type}\n")
    md_content.append(f"**Priority Score**: {dossier.priority_score}/100\n")
    md_content.append(f"**Tier**: {dossier.tier}\n")
    md_content.append(f"**Sections**: {len(dossier.sections)}\n")
    md_content.append(f"**Generation Time**: {dossier.generation_time_seconds:.2f}s\n")
    md_content.append(f"**Estimated Cost**: ${dossier.total_cost_usd:.6f}\n")
    md_content.append(f"**Cache Status**: {dossier.cache_status}\n")

    md_content.append("\n---\n\n")

    # Sections
    md_content.append("## Dossier Sections\n\n")

    for i, section in enumerate(dossier.sections, 1):
        md_content.append(f"### {i}. {section.title}\n\n")
        md_content.append(f"**Generated By**: {section.generated_by.upper()}\n")
        md_content.append(f"**Confidence**: {section.confidence:.2f}\n")
        md_content.append(f"**Generated At**: {section.generated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}\n")

        # Content
        if section.content:
            md_content.append("\n**Content**:\n\n")
            for content_item in section.content:
                md_content.append(f"- {content_item}\n")
            md_content.append("\n")

        # Metrics
        if section.metrics:
            md_content.append("**Metrics**:\n\n")
            for metric in section.metrics:
                if isinstance(metric, dict):
                    label = metric.get('label', 'N/A')
                    value = metric.get('value', 'N/A')
                    md_content.append(f"- **{label}**: {value}\n")
            md_content.append("\n")

        # Insights
        if section.insights:
            md_content.append("**Key Insights**:\n\n")
            for insight in section.insights:
                if isinstance(insight, dict):
                    title = insight.get('title', insight.get('insight', 'N/A'))
                    md_content.append(f"- {title}\n")
                else:
                    md_content.append(f"- {insight}\n")
            md_content.append("\n")

        # Recommendations
        if section.recommendations:
            md_content.append("**Recommendations**:\n\n")
            for rec in section.recommendations:
                if isinstance(rec, dict):
                    title = rec.get('title', rec.get('action', rec.get('recommendation', 'N/A')))
                    priority = rec.get('priority', 'N/A')
                    if priority != 'N/A':
                        md_content.append(f"- **{title}** (Priority: {priority})\n")
                    else:
                        md_content.append(f"- **{title}**\n")
                else:
                    md_content.append(f"- {rec}\n")
            md_content.append("\n")

        md_content.append("---\n\n")

    # Footer
    md_content.append("## Metadata\n\n")
    md_content.append(f"Total Sections: {len(dossier.sections)}\n")
    md_content.append(f"Total Generation Time: {dossier.generation_time_seconds:.2f}s\n")

    model_counts = {}
    for section in dossier.sections:
        model_counts[section.generated_by] = model_counts.get(section.generated_by, 0) + 1

    md_content.append("\n**Model Distribution**:\n")
    for model, count in model_counts.items():
        percentage = (count / len(dossier.sections)) * 100
        md_content.append(f"- {model.upper()}: {count}/{len(dossier.sections)} ({percentage:.0f}%)\n")

    md_content.append("\n---\n\n")
    md_content.append("*Generated by Entity Dossier Generation System*\n")

    # Write to file
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(''.join(md_content))

    return filepath


async def generate_single_dossier(generator, entity_id, entity_name, priority_score):
    """Generate dossier for a single entity"""
    print(f"\n{'=' * 60}")
    print(f"Generating: {entity_name}")
    print(f"Priority: {priority_score}/100")
    print(f"{'=' * 60}")

    try:
        start = datetime.now()

        dossier = await generator.generate_dossier(
            entity_id=entity_id,
            entity_name=entity_name,
            entity_type="CLUB",
            priority_score=priority_score
        )

        end = datetime.now()
        elapsed = (end - start).total_seconds()

        # Save as markdown
        md_path = save_dossier_as_markdown(dossier)

        print(f"‚úÖ SUCCESS - {len(dossier.sections)} sections in {elapsed:.2f}s")
        print(f"   Saved: {md_path}")

        return {
            "entity_name": entity_name,
            "status": "success",
            "sections": len(dossier.sections),
            "time": elapsed,
            "tier": dossier.tier,
            "md_path": md_path
        }

    except Exception as e:
        print(f"‚ùå FAILED: {e}")
        return {
            "entity_name": entity_name,
            "status": "failed",
            "error": str(e)
        }


async def test_batch_processing():
    """Test batch processing with multiple entities"""

    print("=" * 60)
    print("BATCH DOSSIER GENERATION TEST")
    print("=" * 60)

    # Define entities to process
    entities = [
        {"entity_id": "arsenal-fc", "entity_name": "Arsenal FC", "priority_score": 99},
        {"entity_id": "barcelona-fc", "entity_name": "FC Barcelona", "priority_score": 98},
        {"entity_id": "real-madrid", "entity_name": "Real Madrid", "priority_score": 97},
        {"entity_id": "manchester-united", "entity_name": "Manchester United", "priority_score": 96},
        {"entity_id": "liverpool-fc", "entity_name": "Liverpool FC", "priority_score": 95}
    ]

    print(f"\nBatch Size: {len(entities)} entities")
    print(f"Total Expected Sections: {sum(e['priority_score'] > 50 and 11 or e['priority_score'] > 20 and 7 or 3 for e in entities)}")
    print(f"Estimated Total Time: ~{len(entities) * 60}s (~{len(entities)} minutes)")

    # Initialize
    print("\n[1/2] Initializing...")
    client = ClaudeClient()
    generator = EntityDossierGenerator(client, falkordb_client=None)
    print(f"‚úÖ ClaudeClient ready")
    print(f"‚úÖ EntityDossierGenerator ready")

    # Generate dossiers sequentially (to avoid overwhelming the API)
    print(f"\n[2/2] Generating dossiers sequentially...")
    print(f"   (Processing one at a time for API stability)")

    batch_start = datetime.now()
    results = []

    for i, entity in enumerate(entities, 1):
        print(f"\n[{i}/{len(entities)}] Processing {entity['entity_name']}...")
        result = await generate_single_dossier(
            generator,
            entity['entity_id'],
            entity['entity_name'],
            entity['priority_score']
        )
        results.append(result)

    batch_end = datetime.now()
    total_time = (batch_end - batch_start).total_seconds()

    # Summary
    print("\n" + "=" * 60)
    print("BATCH GENERATION SUMMARY")
    print("=" * 60)

    print(f"\nTotal Entities: {len(entities)}")
    print(f"Total Time: {total_time:.2f}s ({total_time/60:.2f} minutes)")
    print(f"Average Time: {total_time/len(entities):.2f}s per entity")

    print("\n" + "-" * 60)
    print("RESULTS")
    print("-" * 60)

    successful = [r for r in results if r['status'] == 'success']
    failed = [r for r in results if r['status'] == 'failed']

    print(f"\n‚úÖ Successful: {len(successful)}/{len(entities)}")
    if successful:
        total_sections = sum(r['sections'] for r in successful)
        avg_time = sum(r['time'] for r in successful) / len(successful)
        print(f"   Total Sections: {total_sections}")
        print(f"   Average Time: {avg_time:.2f}s")

        print(f"\nGenerated Files:")
        for r in successful:
            print(f"   - {r['md_path']}")

    if failed:
        print(f"\n‚ùå Failed: {len(failed)}/{len(entities)}")
        for r in failed:
            print(f"   - {r['entity_name']}: {r['error']}")

    print("\n" + "=" * 60)

    return results


if __name__ == "__main__":
    results = asyncio.run(test_batch_processing())

    print("\n" + "=" * 60)
    print("üìä FINAL STATISTICS")
    print("=" * 60)

    successful = [r for r in results if r['status'] == 'success']

    if successful:
        print(f"\n‚úÖ Batch Processing Complete!")
        print(f"   Entities Processed: {len(successful)}")
        print(f"   Success Rate: {len(successful)/len(results)*100:.0f}%")
        print(f"   Markdown Files: {len(successful)}")
        print(f"   Output Directory: data/dossiers/")
        print("\nüéâ All dossiers saved as markdown for review!")
    else:
        print("\n‚ö†Ô∏è  No dossiers generated successfully")
