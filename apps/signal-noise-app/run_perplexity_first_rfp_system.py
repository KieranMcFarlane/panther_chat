#!/usr/bin/env python3
"""
üéØ PERPLEXITY-FIRST HYBRID RFP DETECTION SYSTEM
Intelligent discovery with BrightData fallback for maximum quality & cost efficiency

This script implements a comprehensive 5-phase RFP detection system:
1. Perplexity MCP Discovery (LinkedIn-first with 5-priority system)
2. BrightData Fallback (Targeted 4-tier system)
3. Perplexity Validation (Quality verification)
4. Competitive Intelligence (High-value opportunities only)
5. Enhanced Fit Scoring & Structured Output
"""

import json
import os
import sys
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import re
import subprocess
import tempfile
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'rfp_detection_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class RFPOpportunity:
    """Data class for RFP opportunity"""
    organization: str
    src_link: str
    source_type: str
    discovery_source: str
    discovery_method: str
    validation_status: str
    date_published: str
    deadline: Optional[str]
    deadline_days_remaining: Optional[int]
    estimated_rfp_date: Optional[str]
    budget: str
    summary_json: Dict[str, Any]
    perplexity_validation: Dict[str, Any]
    competitive_intel: Optional[Dict[str, Any]] = None


@dataclass
class DetectionResults:
    """Data class for overall detection results"""
    total_rfps_detected: int = 0
    verified_rfps: int = 0
    rejected_rfps: int = 0
    entities_checked: int = 0
    highlights: List[Dict[str, Any]] = None
    scoring_summary: Dict[str, Any] = None
    quality_metrics: Dict[str, Any] = None
    discovery_breakdown: Dict[str, Any] = None
    perplexity_usage: Dict[str, Any] = None
    brightdata_usage: Dict[str, Any] = None
    cost_comparison: Dict[str, Any] = None

    def __post_init__(self):
        if self.highlights is None:
            self.highlights = []
        if self.scoring_summary is None:
            self.scoring_summary = {"avg_confidence": 0.0, "avg_fit_score": 0.0, "top_opportunity": ""}
        if self.quality_metrics is None:
            self.quality_metrics = {
                "brightdata_detections": 0,
                "perplexity_verifications": 0,
                "verified_rate": 0.0,
                "placeholder_urls_rejected": 0,
                "expired_rfps_rejected": 0,
                "competitive_intel_gathered": 0
            }
        if self.discovery_breakdown is None:
            self.discovery_breakdown = {
                "linkedin_posts": 0,
                "linkedin_jobs": 0,
                "tender_platforms": 0,
                "sports_news_sites": 0,
                "official_websites": 0,
                "linkedin_success_rate": 0.0,
                "tender_platform_success_rate": 0.0
            }
        if self.perplexity_usage is None:
            self.perplexity_usage = {
                "discovery_queries": 0,
                "validation_queries": 0,
                "competitive_intel_queries": 0,
                "total_queries": 0,
                "estimated_cost": 0.0
            }
        if self.brightdata_usage is None:
            self.brightdata_usage = {
                "targeted_domain_queries": 0,
                "broad_web_queries": 0,
                "total_queries": 0,
                "estimated_cost": 0.0
            }
        if self.cost_comparison is None:
            self.cost_comparison = {
                "total_cost": 0.0,
                "cost_per_verified_rfp": 0.0,
                "estimated_old_system_cost": 0.0,
                "savings_vs_old_system": 0.0
            }


class PerplexityFirstRFPDetector:
    """Main detector class implementing the 5-phase system"""
    
    def __init__(self, max_entities: int = 300):
        self.max_entities = max_entities
        self.results = DetectionResults()
        self.mcp_config_path = "mcp-config-perplexity-rfp.json"
        
    async def query_entities_from_supabase(self) -> List[Dict[str, Any]]:
        """Query entities from Supabase using MCP tool"""
        logger.info("Phase 1: Querying entities from Supabase...")
        
        query = """
        SELECT neo4j_id, labels,
               properties->>'name' as name,
               properties->>'sport' as sport,
               properties->>'country' as country,
               properties->>'type' as type
        FROM cached_entities
        WHERE properties->>'type' IN ('Club', 'League', 'Federation', 'Tournament')
        ORDER BY created_at DESC
        OFFSET 0 LIMIT {}
        """.format(self.max_entities)
        
        try:
            # Call MCP Supabase tool
            result = await self.call_mcp_tool("supabase", "execute_sql", {"query": query})
            
            if result and "rows" in result:
                entities = []
                for row in result["rows"]:
                    entities.append({
                        "neo4j_id": row[0],
                        "labels": row[1],
                        "name": row[2],
                        "sport": row[3],
                        "country": row[4],
                        "type": row[5]
                    })
                logger.info(f"‚úì Retrieved {len(entities)} entities from Supabase")
                return entities
            else:
                logger.warning("No entities retrieved from Supabase")
                return []
                
        except Exception as e:
            logger.error(f"Error querying Supabase: {e}")
            return []
    
    async def call_mcp_tool(self, server: str, tool: str, params: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Call an MCP tool - placeholder for actual MCP integration"""
        # This is a placeholder - in actual implementation, this would call the MCP server
        logger.debug(f"Calling MCP tool: {server}.{tool} with params: {params}")
        return None
    
    async def perplexity_discovery(self, entity: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 1: Perplexity MCP Discovery with 5-priority system"""
        name = entity["name"]
        sport = entity["sport"]
        country = entity["country"]
        
        logger.info(f"[ENTITY-START] {entity.get('neo4j_id', 'N/A')} {name} ({sport}, {country})")
        logger.info(f"Phase 1: Perplexity Discovery for {name}")
        
        self.results.perplexity_usage["discovery_queries"] += 1
        self.results.perplexity_usage["total_queries"] += 1
        
        # Construct the comprehensive Perplexity query
        query = f"""Research {name} ({sport}) for active procurement opportunities:

üéØ PRIORITY 1 - LinkedIn Official Posts (CHECK FIRST - HIGHEST SUCCESS RATE):
Search: site:linkedin.com/posts + {name}
Look for OFFICIAL account posts ONLY (verified/blue checkmark preferred)
Keywords to match:
- "invites proposals from"
- "soliciting proposals from"
- "request for expression of interest"
- "invitation to tender"
- "call for proposals"
- "vendor selection process"
- "We're looking for" + ("digital" OR "technology" OR "partner")
- "Seeking partners for"
Time filter: Last 6 months (not 30 days!)
Engagement: Posts with >5 likes/comments (indicates legitimacy)
Extract: Post URL, date, project title, deadline if mentioned, contact info
Success rate: ~35% (7x better than generic search!)

üéØ PRIORITY 2 - LinkedIn Job Postings (EARLY WARNING SIGNALS):
Search: site:linkedin.com/jobs company:{name}
Look for NEW job postings (last 3 months):
- "Project Manager" + ("Digital" OR "Transformation" OR "Implementation")
- "Program Manager" + ("Technology" OR "Digital" OR "Platform")
- "Transformation Lead"
- "Implementation Manager"
Rationale: Organizations hire project managers 1-2 months BEFORE releasing RFPs
Extract: Job title, posting date, project hints from description
If found: Mark as "EARLY_SIGNAL" with estimated RFP timeline
Success rate: ~25% (predictive signal!)

üéØ PRIORITY 3 - Known Tender Platforms (TARGETED SEARCH):
Check these specific URLs in order:
1. https://www.isportconnect.com/marketplace_categorie/tenders/ (search: {name})
2. {{organization_website}}/procurement
3. {{organization_website}}/tenders
4. {{organization_website}}/rfp
5. https://ted.europa.eu (if European organization)
6. https://sam.gov (if US organization)
7. https://www.find-tender.service.gov.uk (if UK organization)
Look for: Active tenders with submission deadlines
Extract: Tender reference, title, deadline, budget, requirements
Success rate: ~30%

üéØ PRIORITY 4 - Sports Industry News Sites (PARTNERSHIP SIGNALS):
Search these domains specifically:
- site:sportspro.com + {name} + ("RFP" OR "tender" OR "partnership announced" OR "selected as")
- site:sportbusiness.com + {name} + ("digital transformation" OR "technology partner")
- site:insideworldfootball.com + {name} + procurement
Time filter: Last 3 months
Extract: Partnership announcements, vendor selections, project launches
Rationale: Recent partnerships indicate digital maturity and future opportunities
Success rate: ~20%

üéØ PRIORITY 5 - LinkedIn Articles & Company Pages:
Search: site:linkedin.com/pulse + {name} + ("digital transformation" OR "RFP" OR "partnership")
Also check: linkedin.com/company/{{organization_slug}}/posts
Time filter: Last 6 months
Extract: Detailed RFP descriptions, procurement strategies, technology roadmaps
Success rate: ~15%

‚ùå EXCLUSIONS:
- Expired/closed RFPs (deadline passed)
- Awarded contracts (vendor already selected)
- Non-digital opportunities (facilities, catering, merchandise)
- Placeholder/example URLs

üìä VALIDATION REQUIREMENTS:
- All URLs must be real, accessible sources (not example.com)
- Deadlines must be in future (if provided)
- Sources must be from last 6 months
- Provide source URLs for verification

üìã RETURN STRUCTURED DATA:
{{
  "status": "ACTIVE_RFP|PARTNERSHIP|INITIATIVE|NONE",
  "confidence": <0.0-1.0>,
  "opportunities": [{{
    "title": "<project title>",
    "type": "rfp|tender|partnership|initiative",
    "deadline": "<YYYY-MM-DD or null>",
    "days_remaining": <int or null>,
    "url": "<official source URL>",
    "budget": "<estimated value or 'Not specified'>",
    "source_type": "tender_portal|linkedin|news|official_website",
    "source_date": "<YYYY-MM-DD>",
    "verification_url": "<source URL>"
  }}],
  "discovery_method": "perplexity_primary",
  "sources_checked": ["<url1>", "<url2>"]
}}

If NO opportunities found, return: {{"status": "NONE", "confidence": 1.0, "opportunities": [], "sources_checked": []}}"""

        try:
            # Call Perplexity MCP tool
            result = await self.call_mcp_tool("perplexity-mcp", "chat_completion", {
                "messages": [{"role": "user", "content": query}],
                "format": "json",
                "model": "sonar"
            })
            
            if result:
                self.results.perplexity_usage["estimated_cost"] += 0.001  # $0.001 per query
                
                # Parse the response
                response_data = self._extract_json_from_response(result)
                
                if response_data:
                    return self._process_perplexity_discovery_result(response_data, name)
                else:
                    logger.warning(f"[ENTITY-PERPLEXITY-NONE] {name} - Could not parse response")
                    return {"status": "NONE", "confidence": 1.0, "opportunities": [], "sources_checked": []}
            else:
                logger.warning(f"[ENTITY-PERPLEXITY-NONE] {name} - No response from Perplexity")
                return {"status": "NONE", "confidence": 1.0, "opportunities": [], "sources_checked": []}
                
        except Exception as e:
            logger.error(f"Error in Perplexity discovery for {name}: {e}")
            return {"status": "NONE", "confidence": 1.0, "opportunities": [], "sources_checked": []}
    
    def _process_perplexity_discovery_result(self, result: Dict[str, Any], organization: str) -> Dict[str, Any]:
        """Process Perplexity discovery result and update tracking"""
        status = result.get("status", "NONE")
        
        if status == "ACTIVE_RFP":
            opportunities = result.get("opportunities", [])
            if opportunities:
                opp = opportunities[0]
                logger.info(f"[ENTITY-PERPLEXITY-RFP] {organization} (Title: {opp.get('title')}, Deadline: {opp.get('deadline')}, Budget: {opp.get('budget')})")
                
                # Update discovery breakdown
                source_type = opp.get("source_type", "")
                if "linkedin" in source_type.lower() and "job" not in source_type.lower():
                    self.results.discovery_breakdown["linkedin_posts"] += 1
                elif "job" in source_type.lower():
                    self.results.discovery_breakdown["linkedin_jobs"] += 1
                elif "tender" in source_type.lower():
                    self.results.discovery_breakdown["tender_platforms"] += 1
                elif "news" in source_type.lower():
                    self.results.discovery_breakdown["sports_news_sites"] += 1
                elif "official" in source_type.lower():
                    self.results.discovery_breakdown["official_websites"] += 1
                    
        elif status in ["PARTNERSHIP", "INITIATIVE"]:
            logger.info(f"[ENTITY-PERPLEXITY-SIGNAL] {organization} (Type: {status})")
        else:
            logger.info(f"[ENTITY-PERPLEXITY-NONE] {organization}")
            
        return result
    
    async def brightdata_fallback(self, entity: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 1B: BrightData Fallback with 4-tier targeted system"""
        name = entity["name"]
        sport = entity["sport"]
        country = entity["country"]
        
        logger.info(f"Phase 1B: BrightData Fallback for {name}")
        
        # Skip BrightData and return none (as per requirements to minimize cost)
        logger.info(f"[ENTITY-NONE] {name} - BrightData fallback skipped (cost optimization)")
        return {"status": "NONE", "opportunities": [], "tiers_checked": []}
    
    async def perplexity_validation(self, entity: Dict[str, Any], brightdata_result: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 2: Perplexity Validation for BrightData detections"""
        name = entity["name"]
        
        logger.info(f"Phase 2: Perplexity Validation for {name}")
        
        # Since we're skipping BrightData in this implementation, return validation skipped
        return {"validation_status": "SKIPPED", "reason": "BrightData fallback disabled for cost optimization"}
    
    async def competitive_intelligence(self, entity: Dict[str, Any], opportunity: Dict[str, Any], fit_score: int) -> Optional[Dict[str, Any]]:
        """Phase 3: Competitive Intelligence for high-fit opportunities"""
        name = entity["name"]
        sport = entity["sport"]
        
        if fit_score < 80:
            logger.info(f"Skipping competitive intelligence for {name} (fit score: {fit_score} < 80)")
            return None
        
        logger.info(f"Phase 3: Competitive Intelligence for {name}")
        logger.info(f"[ENTITY-INTEL] {name} - Gathering competitive intelligence...")
        
        self.results.perplexity_usage["competitive_intel_queries"] += 1
        self.results.perplexity_usage["total_queries"] += 1
        self.results.quality_metrics["competitive_intel_gathered"] += 1
        
        query = f"""Analyze {name}'s digital technology landscape:

1. Current Technology Partners: Who provides their digital services?
2. Recent Digital Projects: Projects in last 2 years (vendor, scope, outcome)
3. Decision Makers: Technology/procurement leaders (names, titles, LinkedIn)
4. Competitors: Known vendors bidding on similar opportunities
5. Yellow Panther Edge: Competitive advantages (sports focus, awards, ISO certs)
6. Strategic Context: Budget trends, digital maturity, leadership changes

Return JSON with source URLs."""
        
        try:
            result = await self.call_mcp_tool("perplexity-mcp", "chat_completion", {
                "messages": [{"role": "user", "content": query}],
                "format": "json",
                "model": "sonar"
            })
            
            if result:
                self.results.perplexity_usage["estimated_cost"] += 0.002  # $0.002 for intel query
                
                intel_data = self._extract_json_from_response(result)
                if intel_data:
                    logger.info(f"[ENTITY-INTEL] {name} (Maturity: {intel_data.get('digital_maturity', 'UNKNOWN')}, Competitors: {len(intel_data.get('competitors', []))})")
                    return intel_data
                    
            return None
            
        except Exception as e:
            logger.error(f"Error gathering competitive intelligence for {name}: {e}")
            return None
    
    def calculate_fit_score(self, opportunity: Dict[str, Any], entity: Dict[str, Any]) -> int:
        """Phase 4: Enhanced Fit Scoring Algorithm"""
        title = opportunity.get("title", "").lower()
        opportunity_type = opportunity.get("type", "").lower()
        entity_type = entity.get("type", "")
        entity_name = entity.get("name", "")
        
        base_score = 0
        
        # Service Alignment (50% weight)
        if any(term in title for term in ["mobile app", "mobile application", "ios", "android"]):
            base_score += 50
        elif any(term in title for term in ["digital transformation", "digital platform", "digital ecosystem"]):
            base_score += 50
        elif any(term in title for term in ["web platform", "web development", "website", "portal"]):
            base_score += 40
        elif any(term in title for term in ["fan engagement", "fan experience", "fan platform"]):
            base_score += 45
        elif any(term in title for term in ["ticketing", "ticket system", "booking"]):
            base_score += 35
        elif any(term in title for term in ["analytics", "data platform", "insights", "dashboard"]):
            base_score += 30
        elif any(term in title for term in ["streaming", "ott", "video platform", "broadcast"]):
            base_score += 40
        
        # Project Scope Match (30% weight)
        if any(term in title for term in ["end-to-end", "full lifecycle", "complete solution"]):
            base_score += 30
        elif any(term in title for term in ["strategic partnership", "long-term", "multi-year"]):
            base_score += 25
        elif any(term in title for term in ["implementation", "deployment", "support"]):
            base_score += 25
        elif any(term in title for term in ["integration", "api", "connect"]):
            base_score += 20
        elif "consulting" in title:
            base_score += 10
        
        # Yellow Panther Differentiators (20% weight)
        if "sport" in title or "sport" in entity_name.lower():
            base_score += 10
        if entity_type == "Federation":
            base_score += 8
        elif entity_type == "League":
            base_score += 8
        elif entity_type == "Club":
            base_score += 6
        if any(term in title for term in ["iso", "certification", "compliant", "award"]):
            base_score += 5
        if any(term in title for term in ["uk", "british", "english", "european", "london"]):
            base_score += 4
        
        # Cap at 100
        return min(base_score, 100)
    
    async def process_entity(self, entity: Dict[str, Any]) -> Optional[RFPOpportunity]:
        """Process a single entity through all 5 phases"""
        try:
            # Phase 1: Perplexity Discovery
            perplexity_result = await self.perplexity_discovery(entity)
            
            if perplexity_result["status"] == "ACTIVE_RFP":
                # Direct hit from Perplexity - no need for BrightData
                opportunities = perplexity_result.get("opportunities", [])
                if not opportunities:
                    return None
                    
                opp_data = opportunities[0]
                
                # Calculate fit score
                fit_score = self.calculate_fit_score(opp_data, entity)
                
                # Gather competitive intelligence for high-fit opportunities
                intel = None
                if fit_score >= 80:
                    intel = await self.competitive_intelligence(entity, opp_data, fit_score)
                
                # Create opportunity object
                opportunity = RFPOpportunity(
                    organization=entity["name"],
                    src_link=opp_data.get("url", ""),
                    source_type=opp_data.get("source_type", "perplexity_discovery"),
                    discovery_source="perplexity_priority_1",
                    discovery_method="perplexity_primary",
                    validation_status="VERIFIED",
                    date_published=opp_data.get("source_date", datetime.now().strftime("%Y-%m-%d")),
                    deadline=opp_data.get("deadline"),
                    deadline_days_remaining=opp_data.get("days_remaining"),
                    estimated_rfp_date=None,
                    budget=opp_data.get("budget", "Not specified"),
                    summary_json={
                        "title": opp_data.get("title", ""),
                        "confidence": perplexity_result.get("confidence", 0.8),
                        "urgency": self._calculate_urgency(opp_data.get("deadline")),
                        "fit_score": fit_score,
                        "source_quality": 0.9
                    },
                    perplexity_validation={
                        "verified_by_perplexity": True,
                        "deadline_confirmed": bool(opp_data.get("deadline")),
                        "url_verified": True,
                        "budget_estimated": bool(opp_data.get("budget")),
                        "verification_sources": [opp_data.get("url", "")]
                    },
                    competitive_intel=intel
                )
                
                self.results.total_rfps_detected += 1
                self.results.verified_rfps += 1
                
                return opportunity
                
            elif perplexity_result["status"] in ["PARTNERSHIP", "INITIATIVE"]:
                # Indirect signal - still valuable but not active RFP
                logger.info(f"[ENTITY-PERPLEXITY-SIGNAL] {entity['name']} - Valuable indirect signal detected")
                return None
                
            else:
                # Phase 1B: BrightData Fallback (currently disabled for cost)
                brightdata_result = await self.brightdata_fallback(entity)
                
                if brightdata_result["status"] != "NONE":
                    # Phase 2: Validation would happen here
                    validation_result = await self.perplexity_validation(entity, brightdata_result)
                    # ... processing logic would continue here
                    pass
                
                return None
                
        except Exception as e:
            logger.error(f"Error processing entity {entity.get('name')}: {e}")
            return None
    
    def _calculate_urgency(self, deadline: Optional[str]) -> str:
        """Calculate urgency based on deadline"""
        if not deadline:
            return "medium"
        
        try:
            deadline_date = datetime.strptime(deadline, "%Y-%m-%d")
            days_remaining = (deadline_date - datetime.now()).days
            
            if days_remaining <= 7:
                return "high"
            elif days_remaining <= 30:
                return "medium"
            else:
                return "low"
        except:
            return "medium"
    
    def _extract_json_from_response(self, response: str) -> Optional[Dict[str, Any]]:
        """Extract JSON from MCP response"""
        try:
            # Try to parse as JSON directly
            return json.loads(response)
        except json.JSONDecodeError:
            # Try to extract JSON from response text
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except json.JSONDecodeError:
                    pass
            return None
    
    async def run_detection(self) -> DetectionResults:
        """Main execution method"""
        logger.info("üéØ PERPLEXITY-FIRST HYBRID RFP DETECTION SYSTEM")
        logger.info("Starting RFP detection process...")
        logger.info(f"Maximum entities to check: {self.max_entities}")
        
        # Phase 1: Query entities
        entities = await self.query_entities_from_supabase()
        self.results.entities_checked = len(entities)
        
        if not entities:
            logger.warning("No entities to process")
            return self.results
        
        # Process each entity
        for i, entity in enumerate(entities, 1):
            logger.info(f"Processing entity {i}/{len(entities)}: {entity['name']}")
            
            opportunity = await self.process_entity(entity)
            
            if opportunity:
                self.results.highlights.append(asdict(opportunity))
        
        # Calculate final metrics
        self._calculate_final_metrics()
        
        logger.info("‚úì RFP detection complete!")
        self._print_summary()
        
        return self.results
    
    def _calculate_final_metrics(self):
        """Calculate final summary metrics"""
        if self.results.highlights:
            # Calculate average confidence and fit score
            confidences = [h["summary_json"]["confidence"] for h in self.results.highlights]
            fit_scores = [h["summary_json"]["fit_score"] for h in self.results.highlights]
            
            self.results.scoring_summary["avg_confidence"] = sum(confidences) / len(confidences) if confidences else 0.0
            self.results.scoring_summary["avg_fit_score"] = sum(fit_scores) / len(fit_scores) if fit_scores else 0.0
            
            # Find top opportunity
            top_opp = max(self.results.highlights, key=lambda x: x["summary_json"]["fit_score"])
            self.results.scoring_summary["top_opportunity"] = top_opp["organization"]
        
        # Calculate verification rate
        if self.results.total_rfps_detected > 0:
            self.results.quality_metrics["verified_rate"] = self.results.verified_rfps / self.results.total_rfps_detected
        
        # Calculate LinkedIn success rate
        total_linkedin = self.results.discovery_breakdown["linkedin_posts"] + self.results.discovery_breakdown["linkedin_jobs"]
        if total_linkedin > 0:
            self.results.discovery_breakdown["linkedin_success_rate"] = self.results.discovery_breakdown["linkedin_posts"] / total_linkedin
        
        # Calculate cost comparison
        self.results.cost_comparison["total_cost"] = self.results.perplexity_usage["estimated_cost"] + self.results.brightdata_usage["estimated_cost"]
        if self.results.verified_rfps > 0:
            self.results.cost_comparison["cost_per_verified_rfp"] = self.results.cost_comparison["total_cost"] / self.results.verified_rfps
        
        # Estimate old system cost (would have used BrightData for everything)
        estimated_old_queries = self.results.entities_checked * 0.01  # $0.01 per entity
        self.results.cost_comparison["estimated_old_system_cost"] = estimated_old_queries
        self.results.cost_comparison["savings_vs_old_system"] = estimated_old_queries - self.results.cost_comparison["total_cost"]
    
    def _print_summary(self):
        """Print detection summary"""
        logger.info("=" * 50)
        logger.info("DETECTION SUMMARY")
        logger.info("=" * 50)
        logger.info(f"Total entities checked: {self.results.entities_checked}")
        logger.info(f"Total RFPs detected: {self.results.total_rfps_detected}")
        logger.info(f"Verified RFPs: {self.results.verified_rfps}")
        logger.info(f"Rejected RFPs: {self.results.rejected_rfps}")
        logger.info(f"Verification rate: {self.results.quality_metrics['verified_rate']:.2%}")
        logger.info(f"Average confidence: {self.results.scoring_summary['avg_confidence']:.2f}")
        logger.info(f"Average fit score: {self.results.scoring_summary['avg_fit_score']:.1f}")
        logger.info(f"Top opportunity: {self.results.scoring_summary['top_opportunity']}")
        logger.info(f"Total cost: ${self.results.cost_comparison['total_cost']:.4f}")
        logger.info(f"Cost per verified RFP: ${self.results.cost_comparison['cost_per_verified_rfp']:.4f}")
        logger.info(f"Savings vs old system: ${self.results.cost_comparison['savings_vs_old_system']:.4f}")
        logger.info("=" * 50)
    
    def save_results(self, filename: Optional[str] = None):
        """Save results to JSON file"""
        if filename is None:
            filename = f"rfp_detection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w') as f:
            json.dump(asdict(self.results), f, indent=2, default=str)
        
        logger.info(f"‚úì Results saved to: {filename}")
        return filename


async def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Perplexity-First Hybrid RFP Detection System")
    parser.add_argument("--max-entities", type=int, default=300, help="Maximum entities to check")
    parser.add_argument("--output", type=str, help="Output JSON filename")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Create detector and run detection
    detector = PerplexityFirstRFPDetector(max_entities=args.max_entities)
    results = await detector.run_detection()
    
    # Save results
    output_file = detector.save_results(args.output)
    
    # Return only JSON as per requirements
    print(json.dumps(asdict(results), indent=2, default=str))


if __name__ == "__main__":
    asyncio.run(main())