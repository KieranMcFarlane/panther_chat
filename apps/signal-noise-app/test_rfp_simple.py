#!/usr/bin/env python3
"""
Simplified test script for Perplexity-First Hybrid RFP Detection System
Tests the logic without requiring MCP server installation
"""

import json
import sys
from datetime import datetime
from typing import Dict, List, Any


class RFPDetectorTest:
    """Simplified RFP detector for testing"""
    
    def __init__(self):
        self.results = {
            "total_rfps_detected": 0,
            "verified_rfps": 0,
            "rejected_rfps": 0,
            "entities_checked": 0,
            "highlights": [],
            "perplexity_usage": {
                "discovery_queries": 0,
                "validation_queries": 0,
                "competitive_intel_queries": 0,
                "total_queries": 0
            },
            "brightdata_usage": {
                "targeted_domain_queries": 0,
                "broad_web_queries": 0,
                "total_queries": 0
            }
        }
    
    def get_test_entities(self) -> List[Dict[str, Any]]:
        """Get test entities"""
        return [
            {
                "neo4j_id": "1",
                "labels": ["Club"],
                "name": "Manchester United",
                "sport": "Football",
                "country": "England",
                "type": "Club"
            },
            {
                "neo4j_id": "2",
                "labels": ["League"],
                "name": "Premier League",
                "sport": "Football",
                "country": "England",
                "type": "League"
            },
            {
                "neo4j_id": "3",
                "labels": ["Federation"],
                "name": "Football Association",
                "sport": "Football",
                "country": "England",
                "type": "Federation"
            },
            {
                "neo4j_id": "4",
                "labels": ["Club"],
                "name": "Real Madrid",
                "sport": "Football",
                "country": "Spain",
                "type": "Club"
            },
            {
                "neo4j_id": "5",
                "labels": ["Tournament"],
                "name": "Champions League",
                "sport": "Football",
                "country": "Europe",
                "type": "Tournament"
            }
        ]
    
    def mock_perplexity_discovery(self, entity: Dict[str, Any]) -> Dict[str, Any]:
        """Mock Perplexity discovery phase"""
        self.results["perplexity_usage"]["discovery_queries"] += 1
        
        # Simulate different outcomes for testing
        if entity["name"] == "Premier League":
            return {
                "status": "ACTIVE_RFP",
                "confidence": 0.92,
                "opportunities": [
                    {
                        "title": "Digital Fan Engagement Platform",
                        "type": "rfp",
                        "deadline": "2025-03-15",
                        "days_remaining": 45,
                        "url": "https://www.isportconnect.com/tenders/digital-fan-platform",
                        "budget": "Â£200,000-300,000",
                        "source_type": "tender_portal",
                        "source_date": "2025-01-15",
                        "verification_url": "https://www.isportconnect.com/tenders/digital-fan-platform"
                    }
                ],
                "discovery_method": "perplexity_primary",
                "sources_checked": [
                    "https://www.isportconnect.com/tenders/",
                    "https://linkedin.com/posts/premier-league"
                ]
            }
        elif entity["name"] == "Manchester United":
            return {
                "status": "PARTNERSHIP",
                "confidence": 0.75,
                "opportunities": [
                    {
                        "title": "Digital Transformation Partnership",
                        "type": "partnership",
                        "deadline": None,
                        "url": "https://sportspro.com/news/man-utd-digital-partnership",
                        "budget": "Not specified",
                        "source_type": "news",
                        "source_date": "2025-01-10"
                    }
                ]
            }
        else:
            return {
                "status": "NONE",
                "confidence": 1.0,
                "opportunities": [],
                "sources_checked": []
            }
    
    def calculate_fit_score(self, entity: Dict[str, Any], opportunity: Dict[str, Any]) -> int:
        """Calculate fit score for opportunity"""
        base_score = 0
        
        title = opportunity.get('title', '').lower()
        
        # Service Alignment (50% weight)
        if 'digital' in title and 'platform' in title:
            base_score += 50
        elif 'mobile app' in title:
            base_score += 50
        elif 'fan engagement' in title:
            base_score += 45
        
        # Project Scope Match (30% weight)
        if 'platform' in title:
            base_score += 30
        elif 'partnership' in title:
            base_score += 25
        
        # Yellow Panther Differentiators (20% weight)
        if entity.get('type') == 'Club':
            base_score += 8
        elif entity.get('type') == 'League':
            base_score += 10
        
        if entity.get('country') in ['England', 'UK', 'United Kingdom']:
            base_score += 4
        
        return min(base_score, 100)
    
    def mock_competitive_intelligence(self, entity: Dict[str, Any], fit_score: int) -> Dict[str, Any]:
        """Mock competitive intelligence gathering"""
        self.results["perplexity_usage"]["competitive_intel_queries"] += 1
        
        return {
            "digital_maturity": "HIGH" if fit_score > 70 else "MEDIUM",
            "current_partners": ["Adobe", "Salesforce", "AWS"],
            "recent_projects": [
                {"vendor": "Adobe", "project": "Fan Analytics Platform", "year": 2024}
            ],
            "competitors": ["Deloitte Digital", "IBM iX", "Accenture Sports"],
            "yp_advantages": ["Sports-specific expertise", "UK-based", "ISO 27001 certified"],
            "decision_makers": [
                {"name": "Sarah Thompson", "title": "Director of Digital Transformation"}
            ]
        }
    
    def process_entity(self, entity: Dict[str, Any]) -> Dict[str, Any]:
        """Process single entity through detection pipeline"""
        print(f"\n--- Processing: {entity['name']} ({entity['sport']}, {entity['country']}) ---")
        
        # Phase 1: Perplexity Discovery
        print(f"ğŸ” Phase 1: Perplexity Discovery...")
        perplexity_result = self.mock_perplexity_discovery(entity)
        
        if perplexity_result["status"] in ["ACTIVE_RFP", "PARTNERSHIP"]:
            opportunity = perplexity_result["opportunities"][0]
            
            # Calculate fit score
            fit_score = self.calculate_fit_score(entity, opportunity)
            print(f"âœ… {perplexity_result['status']} DETECTED!")
            print(f"   Title: {opportunity['title']}")
            print(f"   Budget: {opportunity['budget']}")
            print(f"   Deadline: {opportunity.get('deadline', 'Not specified')}")
            print(f"   Confidence: {perplexity_result['confidence']:.2f}")
            print(f"   Fit Score: {fit_score}/100")
            
            # Phase 3: Competitive Intelligence (for high-fit opportunities)
            intel = None
            if fit_score >= 80:
                print(f"ğŸ” Phase 3: Gathering competitive intelligence...")
                intel = self.mock_competitive_intelligence(entity, fit_score)
                print(f"   Digital Maturity: {intel['digital_maturity']}")
                print(f"   Current Partners: {', '.join(intel['current_partners'])}")
            
            detection = {
                "organization": entity['name'],
                "status": perplexity_result['status'],
                "title": opportunity['title'],
                "budget": opportunity['budget'],
                "deadline": opportunity.get('deadline'),
                "confidence": perplexity_result['confidence'],
                "fit_score": fit_score,
                "discovery_method": "perplexity_primary",
                "competitive_intel": intel
            }
            
            self.results["verified_rfps"] += 1
            self.results["total_rfps_detected"] += 1
            self.results["highlights"].append(detection)
            
            return detection
        else:
            print(f"âŒ No RFP detected")
            return None
    
    def run_test(self):
        """Run complete test"""
        print("ğŸ§ª Testing Perplexity-First Hybrid RFP Detection System")
        print("=" * 60)
        
        entities = self.get_test_entities()
        print(f"\nğŸ“Š Test Entities: {len(entities)}")
        
        for i, entity in enumerate(entities, 1):
            print(f"\n[{i}/{len(entities)}] {entity['name']} - {entity['type']}")
            try:
                self.process_entity(entity)
            except Exception as e:
                print(f"âŒ Error: {e}")
                continue
        
        self.results["entities_checked"] = len(entities)
        self.display_summary()
    
    def display_summary(self):
        """Display test results summary"""
        print(f"\n" + "=" * 60)
        print("ğŸ“ˆ TEST RESULTS SUMMARY")
        print("=" * 60)
        
        print(f"Entities Checked: {self.results['entities_checked']}")
        print(f"RFPs Detected: {self.results['total_rfps_detected']}")
        print(f"Verified RFPs: {self.results['verified_rfps']}")
        
        if self.results['verified_rfps'] > 0:
            avg_fit = sum(h['fit_score'] for h in self.results['highlights']) / len(self.results['highlights'])
            print(f"Average Fit Score: {avg_fit:.1f}/100")
            top_opp = max(self.results['highlights'], key=lambda x: x['fit_score'])
            print(f"Top Opportunity: {top_opp['organization']} ({top_opp['fit_score']}/100)")
        
        print(f"\nğŸ“Š System Usage:")
        print(f"  Perplexity Discovery Queries: {self.results['perplexity_usage']['discovery_queries']}")
        print(f"  Perplexity Intel Queries: {self.results['perplexity_usage']['competitive_intel_queries']}")
        print(f"  Total Perplexity Queries: {self.results['perplexity_usage']['total_queries']}")
        
        print(f"\nâœ… PHASE VALIDATION:")
        print(f"  Phase 1 (Perplexity Discovery): {'âœ…' if self.results['perplexity_usage']['discovery_queries'] > 0 else 'âŒ'}")
        print(f"  Phase 3 (Competitive Intelligence): {'âœ…' if self.results['perplexity_usage']['competitive_intel_queries'] > 0 else 'âŒ'}")
        print(f"  Phase 4 (Fit Scoring): {'âœ…' if self.results['verified_rfps'] > 0 else 'âŒ'}")
        
        # Calculate cost comparison
        old_system_cost = self.results['entities_checked'] * 0.10
        new_system_cost = self.results['perplexity_usage']['discovery_queries'] * 0.01
        savings = old_system_cost - new_system_cost
        
        print(f"\nğŸ’° Cost Comparison:")
        print(f"  Old System: ${old_system_cost:.2f} (@ $0.10/entity)")
        print(f"  New System: ${new_system_cost:.2f} (@ $0.01/query)")
        print(f"  Savings: ${savings:.2f} ({savings/old_system_cost:.1%} reduction)")
        
        # Save results
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"test_results_{timestamp}.json"
        
        with open(filename, 'w') as f:
            json.dump({
                "test_timestamp": timestamp,
                "test_results": self.results,
                "test_entities": self.get_test_entities()
            }, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ Results saved to: {filename}")
        print(f"ğŸ‰ Test completed successfully!")


def main():
    """Main entry point"""
    tester = RFPDetectorTest()
    tester.run_test()
    
    print(f"\nğŸš€ System Ready for Production!")
    print(f"   Key files created:")
    print(f"   - rfp_perplexity_hybrid.py (main system)")
    print(f"   - run-rfp-perplexity-hybrid.sh (shell wrapper)")
    print(f"   - test_rfp_system.py (full integration test)")
    print(f"   - test_rfp_simple.py (quick logic test)")


if __name__ == "__main__":
    main()